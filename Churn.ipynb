{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# .venv/bin/python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/seokhyunyoon/Downloads/Churn/WA_Fn-UseC_-Telco-Customer-Churn (1).csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "['29.85' '1889.5' '108.15' '1840.75' '151.65' '820.5' '1949.4' '301.9'\n",
      " '3046.05' '3487.95']\n"
     ]
    }
   ],
   "source": [
    "# Checking column types\n",
    "\n",
    "print(df['TotalCharges'].dtype)\n",
    "print(df['TotalCharges'].unique()[:10])  # peek at raw values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID           0\n",
      "gender               0\n",
      "SeniorCitizen        0\n",
      "Partner              0\n",
      "Dependents           0\n",
      "tenure               0\n",
      "PhoneService         0\n",
      "MultipleLines        0\n",
      "InternetService      0\n",
      "OnlineSecurity       0\n",
      "OnlineBackup         0\n",
      "DeviceProtection     0\n",
      "TechSupport          0\n",
      "StreamingTV          0\n",
      "StreamingMovies      0\n",
      "Contract             0\n",
      "PaperlessBilling     0\n",
      "PaymentMethod        0\n",
      "MonthlyCharges       0\n",
      "TotalCharges        11\n",
      "Churn                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['TotalCharges'])\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design Fact & Dimension Tables (Data Warehouse Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_customer = df[['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_services = df[['customerID', 'PhoneService', 'MultipleLines',\n",
    "                   'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "                   'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_contract = df[['customerID', 'Contract', 'PaperlessBilling', 'PaymentMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_customer_activity = df[['customerID', 'tenure', 'MonthlyCharges', 'TotalCharges', 'Churn']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLAP-Style Exploration with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Contract\n",
       "Month-to-month    0.427097\n",
       "One year          0.112772\n",
       "Two year          0.028487\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Churn'] = (df['Churn'] == 'Yes').astype(int)\n",
    "df.groupby('Contract')['Churn'].mean().sort_values(ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InternetService\n",
       "Fiber optic    0.418928\n",
       "DSL            0.189983\n",
       "No             0.074342\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('InternetService')['Churn'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/dh90y6_54t9_vpxl93qn2_dc0000gn/T/ipykernel_5344/2130155945.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby('TenureGroup')['Churn'].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TenureGroup\n",
       "0-12m     0.476782\n",
       "13-24m    0.287109\n",
       "25-48m    0.203890\n",
       "49-72m    0.095132\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TenureGroup'] = pd.cut(df['tenure'], bins=[0, 12, 24, 48, 72], labels=['0-12m', '13-24m', '25-48m', '49-72m'])\n",
    "df.groupby('TenureGroup')['Churn'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PaymentMethod\n",
       "Electronic check             0.452854\n",
       "Mailed check                 0.192020\n",
       "Bank transfer (automatic)    0.167315\n",
       "Credit card (automatic)      0.152531\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('PaymentMethod')['Churn'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/dh90y6_54t9_vpxl93qn2_dc0000gn/T/ipykernel_5344/3845578383.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby('ChargeBucket')['Churn'].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChargeBucket\n",
       "Low       0.109312\n",
       "Medium    0.239837\n",
       "High      0.378499\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ChargeBucket'] = pd.cut(df['MonthlyCharges'], bins=[0, 35, 70, 100], labels=['Low', 'Medium', 'High'])\n",
    "df.groupby('ChargeBucket')['Churn'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_telco_churn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.drop(['customerID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_model, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop('Churn', axis=1).values\n",
    "y = df_encoded['Churn'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "smote = SMOTE()\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#3. Train the Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train_res.shape[1], 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define & Train Your PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Import PyTorch and Prepare Tensors\n",
    "\n",
    "# Convert to numpy arrays first if they aren't already\n",
    "X_train_res = np.array(X_train_res, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_train_res = np.array(y_train_res, dtype=np.float32)\n",
    "y_tests = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train_scaled).float()\n",
    "X_test_tensor = torch.from_numpy(X_test_scaled).float()\n",
    "\n",
    "# Now create tensors\n",
    "X_train_tensor = torch.from_numpy(X_train_res).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_res.reshape(-1, 1)).float()\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "y_test_tensor = torch.from_numpy(y_test.reshape(-1, 1)).float()\n",
    "\n",
    "# Create DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define the Neural Network\n",
    "class ChurnNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ChurnNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = ChurnNet(input_dim=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 93.2702\n",
      "Epoch 2/100, Loss: 89.0097\n",
      "Epoch 3/100, Loss: 88.1608\n",
      "Epoch 4/100, Loss: 87.2554\n",
      "Epoch 5/100, Loss: 87.5533\n",
      "Epoch 6/100, Loss: 86.9431\n",
      "Epoch 7/100, Loss: 87.5652\n",
      "Epoch 8/100, Loss: 86.6726\n",
      "Epoch 9/100, Loss: 86.6474\n",
      "Epoch 10/100, Loss: 86.5001\n",
      "Epoch 11/100, Loss: 86.4577\n",
      "Epoch 12/100, Loss: 87.5083\n",
      "Epoch 13/100, Loss: 87.3151\n",
      "Epoch 14/100, Loss: 86.4932\n",
      "Epoch 15/100, Loss: 86.2660\n",
      "Epoch 16/100, Loss: 87.1266\n",
      "Epoch 17/100, Loss: 86.9949\n",
      "Epoch 18/100, Loss: 86.7648\n",
      "Epoch 19/100, Loss: 86.3999\n",
      "Epoch 20/100, Loss: 86.6441\n",
      "Epoch 21/100, Loss: 86.5821\n",
      "Epoch 22/100, Loss: 86.3198\n",
      "Epoch 23/100, Loss: 86.9167\n",
      "Epoch 24/100, Loss: 87.2122\n",
      "Epoch 25/100, Loss: 87.2029\n",
      "Epoch 26/100, Loss: 86.5034\n",
      "Epoch 27/100, Loss: 87.1707\n",
      "Epoch 28/100, Loss: 86.6036\n",
      "Epoch 29/100, Loss: 86.3410\n",
      "Epoch 30/100, Loss: 86.3165\n",
      "Epoch 31/100, Loss: 86.3758\n",
      "Epoch 32/100, Loss: 87.0807\n",
      "Epoch 33/100, Loss: 85.9800\n",
      "Epoch 34/100, Loss: 85.9807\n",
      "Epoch 35/100, Loss: 86.6561\n",
      "Epoch 36/100, Loss: 86.4989\n",
      "Epoch 37/100, Loss: 87.1330\n",
      "Epoch 38/100, Loss: 86.9096\n",
      "Epoch 39/100, Loss: 86.0832\n",
      "Epoch 40/100, Loss: 86.4275\n",
      "Epoch 41/100, Loss: 86.8624\n",
      "Epoch 42/100, Loss: 86.4572\n",
      "Epoch 43/100, Loss: 86.0689\n",
      "Epoch 44/100, Loss: 86.6390\n",
      "Epoch 45/100, Loss: 85.9099\n",
      "Epoch 46/100, Loss: 85.9570\n",
      "Epoch 47/100, Loss: 86.6572\n",
      "Epoch 48/100, Loss: 86.7627\n",
      "Epoch 49/100, Loss: 86.2444\n",
      "Epoch 50/100, Loss: 86.6127\n",
      "Epoch 51/100, Loss: 85.5557\n",
      "Epoch 52/100, Loss: 85.8585\n",
      "Epoch 53/100, Loss: 86.1501\n",
      "Epoch 54/100, Loss: 85.6651\n",
      "Epoch 55/100, Loss: 86.0196\n",
      "Epoch 56/100, Loss: 86.0886\n",
      "Epoch 57/100, Loss: 85.9792\n",
      "Epoch 58/100, Loss: 85.3493\n",
      "Epoch 59/100, Loss: 85.7466\n",
      "Epoch 60/100, Loss: 85.6855\n",
      "Epoch 61/100, Loss: 86.0944\n",
      "Epoch 62/100, Loss: 86.2890\n",
      "Epoch 63/100, Loss: 85.3394\n",
      "Epoch 64/100, Loss: 85.4920\n",
      "Epoch 65/100, Loss: 85.9287\n",
      "Epoch 66/100, Loss: 84.9147\n",
      "Epoch 67/100, Loss: 86.0559\n",
      "Epoch 68/100, Loss: 84.8032\n",
      "Epoch 69/100, Loss: 85.5153\n",
      "Epoch 70/100, Loss: 85.1178\n",
      "Epoch 71/100, Loss: 85.1637\n",
      "Epoch 72/100, Loss: 85.6613\n",
      "Epoch 73/100, Loss: 85.9731\n",
      "Epoch 74/100, Loss: 86.2432\n",
      "Epoch 75/100, Loss: 85.8671\n",
      "Epoch 76/100, Loss: 86.2170\n",
      "Epoch 77/100, Loss: 86.1142\n",
      "Epoch 78/100, Loss: 85.4178\n",
      "Epoch 79/100, Loss: 85.7986\n",
      "Epoch 80/100, Loss: 84.6595\n",
      "Epoch 81/100, Loss: 85.8512\n",
      "Epoch 82/100, Loss: 85.7177\n",
      "Epoch 83/100, Loss: 85.0785\n",
      "Epoch 84/100, Loss: 86.2590\n",
      "Epoch 85/100, Loss: 85.0236\n",
      "Epoch 86/100, Loss: 85.7091\n",
      "Epoch 87/100, Loss: 85.8348\n",
      "Epoch 88/100, Loss: 85.6734\n",
      "Epoch 89/100, Loss: 85.1369\n",
      "Epoch 90/100, Loss: 85.4432\n",
      "Epoch 91/100, Loss: 85.8688\n",
      "Epoch 92/100, Loss: 85.1716\n",
      "Epoch 93/100, Loss: 85.1138\n",
      "Epoch 94/100, Loss: 85.0741\n",
      "Epoch 95/100, Loss: 85.6276\n",
      "Epoch 96/100, Loss: 85.4359\n",
      "Epoch 97/100, Loss: 84.7687\n",
      "Epoch 98/100, Loss: 85.6507\n",
      "Epoch 99/100, Loss: 84.7467\n",
      "Epoch 100/100, Loss: 84.8618\n"
     ]
    }
   ],
   "source": [
    "#4. Train the Model\n",
    "# First, define the neural network model\n",
    "class EnhancedChurnModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.net(x))\n",
    "    \n",
    "# Create the model instance\n",
    "input_size = X_train_res.shape[1]  # Number of features\n",
    "model = EnhancedChurnModel(input_size)\n",
    "\n",
    "# Now define the loss function and optimizer\n",
    "#criterion = nn.BCELoss() #replace this with the following code\n",
    "# Calculate class weights\n",
    "pos_weight = torch.tensor([sum(y_train == 0) / sum(y_train == 1)], dtype=torch.float32)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# (Optional) Weighted Random Sampler for DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "weights = torch.where(torch.from_numpy(y_train).float() == 1, \n",
    "                     torch.tensor([sum(y_train == 0) / sum(y_train == 1)]), \n",
    "                     torch.tensor(1.0))\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "train_loader = DataLoader(train_data, batch_size=64, sampler=sampler)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6183368869936035\n",
      "Confusion Matrix:\n",
      " [[524 509]\n",
      " [ 28 346]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     0.507     0.661      1033\n",
      "         1.0      0.405     0.925     0.563       374\n",
      "\n",
      "    accuracy                          0.618      1407\n",
      "   macro avg      0.677     0.716     0.612      1407\n",
      "weighted avg      0.805     0.618     0.635      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2. Evaluate with Accuracy and Confusion Matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "#1. Make Predictions on Test Set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_probs = model(X_test_tensor)\n",
    "    y_pred_labels = (y_pred_probs > 0.5).float()\n",
    "\n",
    "\n",
    "# Convert to NumPy\n",
    "y_true = y_test_tensor.numpy()\n",
    "y_pred = y_pred_labels.numpy()\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Precision, Recall, F1\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
